{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "73eeee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import traceback\n",
    "import os\n",
    "import torch\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# LangChain Local Providers\n",
    "# from langchain_community.llms import Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "import json\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d85ca25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is required to run LangGraph's async loops in a Jupyter Notebook\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8836685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stockanalyzer.crew import SUPERVISOR_PROMPT, WORKER_PROMPT, SYNTHESIS_PROMPT\n",
    "from stockanalyzer.crew import AgentState, ContextSchema\n",
    "from stockanalyzer.crew import SupervisorPlan, create_worker_node\n",
    "\n",
    "from stockanalyzer.config import QWEN_3, GEMINI_2_5_FLASH\n",
    "from stockanalyzer.config import Config, ModelProvider, ModelConfig\n",
    "\n",
    "from stockanalyzer.tools import get_historical_stock_price, fetch_sec_filing_sections, Section \n",
    "\n",
    "from edgar import set_identity\n",
    "set_identity(\"abc@123.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a8db304a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelConfig(name='qwen2.5:1.5b', temperature=0.0, provider=<ModelProvider.OLLAMA: 'ollama'>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.MODEL = ModelConfig(\"qwen2.5:1.5b\", temperature=0.0, provider=ModelProvider.OLLAMA)\n",
    "Config.MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c4880582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copied from main.py\n",
    "def create_model():\n",
    "    parameters = {\n",
    "        \"temperature\": Config.MODEL.temperature,\n",
    "        \"thinking_budget\": 0\n",
    "    }\n",
    "    if Config.MODEL.provider == ModelProvider.OLLAMA:\n",
    "        parameters[\"num_ctx\"] = Config.CONTEXT_WINDOW\n",
    "        \n",
    "    return init_chat_model(\n",
    "        f\"{Config.MODEL.provider.value}:{Config.MODEL.name}\",\n",
    "        **parameters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f32df00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model type: <class 'langchain_community.chat_models.ollama.ChatOllama'>\n",
      "model: model='qwen2.5:1.5b' num_ctx=8192 temperature=0.0\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "print(f'model type: {type(model)}')\n",
    "print(f'model: {model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8aca724a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function stockanalyzer.crew.create_worker_node.<locals>.worker_node(state: stockanalyzer.crew.AgentState, runtime: langgraph.runtime.Runtime[stockanalyzer.crew.ContextSchema])>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pricing_analyst = create_worker_node(\"Price Analyst\", [get_historical_stock_price])\n",
    "pricing_analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a03fbb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentState(messages=[HumanMessage(content='Analyze NVDIA stock performance based on historical data.', additional_kwargs={}, response_metadata={}, name='SupervisorInstruction')], iteration_count=1, next_agent='Pricing Analyst')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty instance of AgentState\n",
    "state = AgentState(\n",
    "        messages = [HumanMessage(content=\"Analyze NVDIA stock performance based on historical data.\"\n",
    "                                  , name=\"SupervisorInstruction\")],\n",
    "        next_agent = \"Pricing Analyst\",\n",
    "        iteration_count = 1\n",
    "    )\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "02589060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example tool call\n",
    "def tool_call(agent_name: str, state: AgentState, tools: list, model):\n",
    "    \"\"\"\n",
    "    A legacy-compatible tool call function that doesn't rely on .bind_tools().\n",
    "    Works with langchain-core < 0.3.0 and ChatOllama.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Manually construct the tool definitions for the prompt\n",
    "    tool_defs = []\n",
    "    for t in tools:\n",
    "        tool_defs.append({\n",
    "            \"name\": t.name,\n",
    "            \"description\": t.description,\n",
    "            \"parameters\": t.args if hasattr(t, 'args') else \"Expects a ticker string\"\n",
    "        })\n",
    "\n",
    "    # 2. Build a strict system instruction for JSON output\n",
    "    system_instruction = (\n",
    "        f\"You are the {agent_name}. Your task is to process instructions by choosing a tool.\\n\"\n",
    "        f\"AVAILABLE TOOLS:\\n{json.dumps(tool_defs, indent=2)}\\n\\n\"\n",
    "        f\"INSTRUCTION: {state.messages[-1].content}\\n\\n\"\n",
    "        f\"You MUST respond ONLY with a JSON object in this format:\\n\"\n",
    "        f\"{{\\\"tool_name\\\": \\\"name_of_tool\\\", \\\"args\\\": {{\\\"param_name\\\": \\\"value\\\"}}}}\\n\"\n",
    "        f\"Do not include any other text or explanations.\"\n",
    "    )\n",
    "    \n",
    "    # 3. Invoke the model\n",
    "    # Note: Using invoke() which is supported in your version, but without tool binding\n",
    "    response = model.invoke([HumanMessage(content=system_instruction)])\n",
    "    \n",
    "    try:\n",
    "        # 4. Clean and parse the response\n",
    "        content = response.content\n",
    "        # Find the JSON block if the model added markdown backticks\n",
    "        json_match = re.search(r\"\\{.*\\}\", content, re.DOTALL)\n",
    "        if json_match:\n",
    "            data = json.loads(json_match.group(0))\n",
    "            \n",
    "            # 5. Manually construct an AIMessage with tool_calls for downstream compatibility\n",
    "            # In older LangChain, we simulate the tool_call structure\n",
    "            return AIMessage(\n",
    "                content=\"\",\n",
    "                additional_kwargs={\n",
    "                    \"tool_calls\": [{\n",
    "                        \"id\": \"call_\" + str(hash(content)),\n",
    "                        \"function\": {\n",
    "                            \"name\": data[\"tool_name\"],\n",
    "                            \"arguments\": json.dumps(data[\"args\"])\n",
    "                        },\n",
    "                        \"type\": \"function\"\n",
    "                    }]\n",
    "                }\n",
    "            )\n",
    "    except Exception as e:\n",
    "        # Return a fallback message if parsing fails\n",
    "        return AIMessage(content=f\"Error parsing tool call: {str(e)}\")\n",
    "\n",
    "# Usage example in your notebook:\n",
    "# response = tool_call(\"Pricing Analyst\", state, [get_historical_stock_price], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "093ebe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the tool call\n",
    "tool_call_response_price_analyst = tool_call(\"Pricing Analyst\", state, [get_historical_stock_price], model)\n",
    "tool_call_response_filing_analyst = tool_call(\"Filing Analyst\", state, [fetch_sec_filing_sections], model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cf6412cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_historical_stock_price',\n",
       "  'args': {'ticker': 'NVDA'},\n",
       "  'id': 'call_4389698801266433013',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call_response_price_analyst.tool_calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9806520b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'fetch_sec_filing_sections',\n",
       " 'args': {'ticker': 'NVDA', 'sections': ['income_statement']},\n",
       " 'id': 'call_-3450241622400116513',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call_response_filing_analyst.tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_output_price = get_historical_stock_price.invoke(tool_call_response_price_analyst.tool_calls[0][\"args\"])\n",
    "# tool_output = get_historical_stock_price.func(tool_call_response_price_analyst.tool_calls[0][\"args\"][\"ticker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b5be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7460"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_output_filing = fetch_sec_filing_sections.invoke(tool_call_response_filing_analyst.tool_calls[0][\"args\"])\n",
    "len(tool_output_filing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1ffbdaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_messages = [ToolMessage(content=str(tool_output_filing), \n",
    "                            tool_call_id=tool_call_response_filing_analyst.tool_calls[0]['id'],\n",
    "                            name=tool_call_response_filing_analyst.tool_calls[0][\"name\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "db19078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_response = model.invoke(\n",
    "    WORKER_PROMPT.format(\n",
    "        agent_name=\"Filing Analyst\",\n",
    "        supervisor_instruction=\"Analyze NVDIA stock performance based on historical data.\",\n",
    "        tool_data=tool_messages[0].content # Only one tool call (so far)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ccfa55fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='NVIDIA CORP Stock Performance Analysis\\n\\nKey Findings:\\n\\n1. **Revenue Growth**: The company reported a significant increase in revenue across all segments, with Compute & Networking and Graphics experiencing substantial growth.\\n2. **Operating Income**: Operating income increased by 57% year-over-year, driven primarily by higher gross profit margins and reduced operating expenses.\\n3. **Net Income**: Net income also saw an impressive rise of 109%, reflecting improved profitability across all segments.\\n\\nThese findings indicate a strong financial performance with robust growth in revenue and net income, particularly in key segments like Compute & Networking and Graphics.', additional_kwargs={}, response_metadata={'model': 'qwen2.5:1.5b', 'created_at': '2026-01-01T02:45:10.7154849Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'done_reason': 'stop', 'total_duration': 85340411700, 'load_duration': 2111083600, 'prompt_eval_count': 1712, 'prompt_eval_duration': 73381895200, 'eval_count': 124, 'eval_duration': 9356830500}, id='lc_run--f08c42a6-05a4-4e22-a54e-e032a11e080f-0')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e0ac2989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA CORP Stock Performance Analysis\n",
      "\n",
      "Key Findings:\n",
      "\n",
      "1. **Revenue Growth**: The company reported a significant increase in revenue across all segments, with Compute & Networking and Graphics experiencing substantial growth.\n",
      "2. **Operating Income**: Operating income increased by 57% year-over-year, driven primarily by higher gross profit margins and reduced operating expenses.\n",
      "3. **Net Income**: Net income also saw an impressive rise of 109%, reflecting improved profitability across all segments.\n",
      "\n",
      "These findings indicate a strong financial performance with robust growth in revenue and net income, particularly in key segments like Compute & Networking and Graphics.\n"
     ]
    }
   ],
   "source": [
    "print(summary_response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
